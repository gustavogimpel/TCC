{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "MONGODB_HOST = \"192.168.0.15\"\n",
    "MONGODB_PORT = \"27017\"\n",
    "MAX_WORKERS = 4\n",
    "ITERATIONS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_collections_debug = [\"100\",\"500\",\"1000\",\"5000\",\"10000\",\"50000\",\"100000\",\"500000\",\"1000000\"]\n",
    "arr_collections = [\"100\",\"500\",\"1000\",\"5000\",\"10000\",\"50000\",\"100000\",\"500000\",\"1000000\",\"5000000\",\"8000000\"]\n",
    "\n",
    "df = None\n",
    "#.config(\"spark.shuffle.service.enabled\", True) \\\n",
    "#.config(\"spark.dynamicAllocation.enabled\", True) \\\n",
    "#.config(\"spark.dynamicAllocation.minExecutors\", MAX_WORKERS) \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"io_tests_mongodb\") \\\n",
    "    .master(\"spark://spark:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n",
    "    \n",
    "def getCollectionReadURL(collection):\n",
    "    return \"mongodb://\" + MONGODB_HOST + \":\" + MONGODB_PORT + \"/yelp_filtered_read.\" + collection + \"?ssl=false\"\n",
    "\n",
    "def getCollectionWriteURL(collection):\n",
    "    return \"mongodb://\" + MONGODB_HOST + \":\" + MONGODB_PORT + \"/yelp_filtered_write.\" + collection + \"?ssl=false\"\n",
    "\n",
    "def readFromCollection(url):\n",
    "    return spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", url).load()\n",
    "    \n",
    "def writeToCollection(df, url):\n",
    "    df.write.format(\"mongo\").mode(\"append\").option(\"uri\", url).save()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TESTE DE LEITURA DOS ARQUIVOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored: 11.437923399999988\n",
      "[01] 100000: 5.394 segundos\n",
      "[02] 100000: 4.17 segundos\n",
      "[03] 100000: 4.281 segundos\n",
      "[04] 100000: 3.835 segundos\n",
      "[05] 100000: 3.842 segundos\n",
      "[06] 100000: 3.979 segundos\n",
      "[07] 100000: 4.238 segundos\n",
      "[08] 100000: 4.218 segundos\n",
      "[09] 100000: 3.815 segundos\n",
      "[10] 100000: 3.849 segundos\n",
      "[11] 100000: 3.784 segundos\n",
      "[12] 100000: 3.725 segundos\n",
      "[13] 100000: 3.928 segundos\n",
      "[14] 100000: 3.807 segundos\n",
      "[15] 100000: 3.731 segundos\n",
      "[16] 100000: 3.909 segundos\n",
      "[17] 100000: 3.892 segundos\n",
      "[18] 100000: 3.796 segundos\n",
      "[19] 100000: 3.915 segundos\n",
      "[20] 100000: 3.702 segundos\n",
      "[21] 100000: 3.845 segundos\n",
      "[22] 100000: 3.878 segundos\n",
      "[23] 100000: 3.988 segundos\n",
      "[24] 100000: 3.879 segundos\n",
      "[25] 100000: 3.789 segundos\n",
      "[26] 100000: 3.739 segundos\n",
      "[27] 100000: 3.8 segundos\n",
      "[28] 100000: 3.905 segundos\n",
      "[29] 100000: 4.016 segundos\n",
      "[30] 100000: 3.827 segundos\n"
     ]
    }
   ],
   "source": [
    "firstRun = True\n",
    "arr_collection_sizes = {}\n",
    "arr_collection_read_timings = {}\n",
    "for collection in arr_collections_debug:\n",
    "    arr_sizes = []\n",
    "    arr_timings = []    \n",
    "    for i in range(30):\n",
    "        \n",
    "        url = getCollectionReadURL(collection)\n",
    "        \n",
    "        starttime = timer()\n",
    "        df = readFromCollection(url)\n",
    "        count = df.count()\n",
    "        endtime = timer()\n",
    "        \n",
    "        if(firstRun):\n",
    "            print(\"Ignored: \" + str(endtime-starttime))\n",
    "            firstRun = False\n",
    "            starttime = timer()\n",
    "            df = readFromCollection(url)\n",
    "            count = df.count()\n",
    "            endtime = timer()\n",
    "        \n",
    "        size = sys.getsizeof(df)\n",
    "        \n",
    "        arr_sizes.append(size)\n",
    "        arr_timings.append(endtime-starttime)\n",
    "        print(\"[\"+\"{:02d}\".format(i+1)+\"] \"+ str(count) + \": \" + str(round(endtime-starttime, 3)) + \" segundos\")\n",
    "        \n",
    "    arr_collection_sizes[collection] = str(np.mean(arr_sizes)) + \" kb\"\n",
    "    arr_collection_read_timings[collection] = str(round(np.mean(arr_timings), 3)) + \" segundos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TESTE DE ESCRITA DOS ARQUIVOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored: 12.791313099999911\n",
      "[01] 100000: 10.992 segundos\n",
      "[02] 100000: 10.816 segundos\n",
      "[03] 100000: 10.351 segundos\n",
      "[04] 100000: 10.513 segundos\n",
      "[05] 100000: 10.287 segundos\n",
      "[06] 100000: 9.778 segundos\n",
      "[07] 100000: 9.427 segundos\n",
      "[08] 100000: 9.873 segundos\n",
      "[09] 100000: 9.115 segundos\n",
      "[10] 100000: 9.889 segundos\n",
      "[11] 100000: 8.759 segundos\n",
      "[12] 100000: 9.894 segundos\n",
      "[13] 100000: 9.841 segundos\n",
      "[14] 100000: 9.938 segundos\n",
      "[15] 100000: 8.861 segundos\n",
      "[16] 100000: 8.15 segundos\n",
      "[17] 100000: 9.808 segundos\n",
      "[18] 100000: 10.002 segundos\n",
      "[19] 100000: 9.112 segundos\n",
      "[20] 100000: 10.257 segundos\n",
      "[21] 100000: 10.279 segundos\n",
      "[22] 100000: 10.603 segundos\n",
      "[23] 100000: 10.19 segundos\n",
      "[24] 100000: 10.111 segundos\n",
      "[25] 100000: 10.212 segundos\n",
      "[26] 100000: 9.895 segundos\n",
      "[27] 100000: 9.136 segundos\n",
      "[28] 100000: 9.328 segundos\n",
      "[29] 100000: 9.723 segundos\n",
      "[30] 100000: 9.907 segundos\n"
     ]
    }
   ],
   "source": [
    "firstRun = True\n",
    "arr_collection_write_timings = {}\n",
    "for collection in arr_collections_debug:\n",
    "    urlRead = getCollectionReadURL(collection)\n",
    "    df = readFromCollection(urlRead)\n",
    "    count = df.count()\n",
    "    arr_timings = []    \n",
    "    for i in range(30):\n",
    "        url = getCollectionWriteURL(collection)\n",
    "        \n",
    "        starttime = timer()\n",
    "        writeToCollection(df, url)\n",
    "        endtime = timer()\n",
    "        \n",
    "        if(firstRun):\n",
    "            print(\"Ignored: \" + str(endtime-starttime))\n",
    "            firstRun = False\n",
    "            starttime = timer()\n",
    "            writeToCollection(df, url)\n",
    "            endtime = timer()\n",
    "        \n",
    "        arr_timings.append(endtime-starttime)\n",
    "        print(\"[\"+\"{:02d}\".format(i+1)+\"] \"+ str(count) + \": \" + str(round(endtime-starttime, 3)) + \" segundos\")\n",
    "        \n",
    "    arr_collection_write_timings[collection] = str(round(np.mean(arr_timings), 3)) + \" segundos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MÉDIA DO TEMPO DE LEITURA DOS ARQUIVOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100000': '3.949 segundos'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_collection_read_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MÉDIA DO TEMPO DE ESCRITA DOS ARQUIVOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100000': '9.835 segundos'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_collection_write_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MÉDIA DO TAMANHO DOS ARQUIVOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100000': '56.0 kb'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_collection_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
