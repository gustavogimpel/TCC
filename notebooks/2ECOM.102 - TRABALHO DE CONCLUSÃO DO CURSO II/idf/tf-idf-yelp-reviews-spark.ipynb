{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json, codecs, os\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.sql.functions import collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_collections_debug = [\"8000000\"]\n",
    "arr_collections = [\"100\",\"500\",\"1000\",\"5000\",\"10000\",\"50000\",\"100000\",\"500000\",\"1000000\"]#,\"5000000\",\"8000000\"]\n",
    "MONGO_HOST = \"192.168.0.15\"\n",
    "MONGO_PORT = \"27017\"\n",
    "firstRun = True\n",
    "\n",
    "review_df = None\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"tfidf_spark\") \\\n",
    "    .master(\"spark://spark:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "def getCollectionReadURL(collection):\n",
    "    return \"mongodb://\" + MONGO_HOST + \":\" + MONGO_PORT + \"/yelp_filtered_read.\" + collection + \"?ssl=false\"\n",
    "\n",
    "def readFromCollection(collection, profile=False):\n",
    "    url = getCollectionReadURL(collection)\n",
    "    df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", url).load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review_df):\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "    return tokenizer.transform(review_df)\n",
    "\n",
    "def vectorize(review_df):\n",
    "    countVectorizer = CountVectorizer(inputCol='words', outputCol='vectorizer', minDF=3).fit(review_df)\n",
    "    return countVectorizer.transform(review_df)\n",
    "\n",
    "def idf(review_df):\n",
    "    idf = IDF(inputCol=\"vectorizer\", outputCol=\"tfidf_features\").fit(review_df)\n",
    "    return idf.transform(review_df)\n",
    "\n",
    "def process(review_df):\n",
    "    grouped_df = review_df.groupBy(\"business_id\").agg(collect_list('text').alias(\"text\"))\n",
    "    grouped_df = grouped_df.withColumn(\"text\", concat_ws(\" \", col(\"text\")))\n",
    "    grouped_df = tokenize(grouped_df)\n",
    "    grouped_df = vectorize(grouped_df)\n",
    "    grouped_df = idf(grouped_df)\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arr_collection_timings = {}\n",
    "for collection in arr_collections_debug:\n",
    "    review_df = readFromCollection(collection)\n",
    "    count = review_df.count()\n",
    "    arr_timings = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        starttime = timer()\n",
    "        grouped_df = process(review_df)\n",
    "        endtime = timer()\n",
    "        \n",
    "        if(firstRun):\n",
    "            print(\"Ignored: \" + str(endtime-starttime))\n",
    "            firstRun = False\n",
    "            starttime = timer()\n",
    "            grouped_df = process(review_df)\n",
    "            endtime = timer()\n",
    "        \n",
    "        arr_timings.append(endtime-starttime)\n",
    "        print(\"[\"+\"{:02d}\".format(i+1)+\"] \"+ str(count) + \": \" + str(round(endtime-starttime, 3)) + \" segundos\")\n",
    "        \n",
    "    arr_collection_timings[collection] = round(np.mean(arr_timings), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bellagio Gallery of Fine Art\n",
    "#company_df1 = review_df[review_df['business_id'] == \"-MhfebM0QIsKt87iDN-FNw\"]\n",
    "\n",
    "#The Empanadas House\n",
    "#company_df2 = review_df[review_df['business_id'] == \"pQeaRpvuhoEqudo3uymHIQ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company_df1.select(\"vectorizer\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company_df2.select(\"vectorizer\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_collection_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
