{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URL_INPUT = \"mongodb://192.168.0.20:27017/yelp.review?ssl=false\"\n",
    "MONGO_URL_OUTPUT = \"mongodb://192.168.0.20:27017/yelp.teste\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"kmeans-spark\") \\\n",
    "    .master(\"spark://spark:7077\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", MONGO_URL_INPUT) \\\n",
    "    .config(\"spark.mongodb.output.uri\", MONGO_URL_OUTPUT) \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.0')\\\n",
    "    .getOrCreate()\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "def getDataFrame() {\n",
    "    df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "}\n",
    "\n",
    "cProfile.run('getDataFrame()')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark withColumn() is a DataFrame function that is used to add a new column to DataFrame, change the value of an existing column, convert the datatype of a column, derive a new column from an existing column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_COL = ['review_count', 'useful', 'funny', 'cool', 'fans', 'average_stars']\n",
    "for col in df.columns:\n",
    "    if col in FEATURES_COL:\n",
    "        df = df.withColumn(col, df[col].cast('float'))\n",
    "    else:\n",
    "        df = df.drop(col)\n",
    "df = df.na.drop()\n",
    "df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark's implementation of KMeans is a bit different from for example scikit-learn's version. We need to store all features as an array of floats, and store this array as a column called \"features\". Since we do no longer need the original columns we filter them out with a select statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=FEATURES_COL, outputCol=\"features\")\n",
    "df_kmeans = vecAssembler.transform(df)\n",
    "df_kmeans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
    "model = kmeans.fit(df_kmeans)\n",
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(df_kmeans)\n",
    "rows = transformed.collect()\n",
    "print(rows[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = sqlContext.createDataFrame(rows)\n",
    "df_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf_pred = df_pred.toPandas()\n",
    "pddf_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedee = plt.figure(figsize=(12,10)).gca(projection='3d')\n",
    "threedee.scatter(pddf_pred.average_stars, pddf_pred.cool, pddf_pred.fans, c=pddf_pred.prediction)\n",
    "threedee.set_xlabel('x')\n",
    "threedee.set_ylabel('y')\n",
    "threedee.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
